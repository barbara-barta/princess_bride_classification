{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be940c5",
   "metadata": {},
   "source": [
    "First we import essential libraries that we'll use throughout the notebook. These include tools for numerical computation (NumPy), image processing (OpenCV), plotting (Matplotlib), and managing files and directories (os, shutil, and Path)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f37587a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e56e24",
   "metadata": {},
   "source": [
    "Next we load a sample image from the test_data folder using OpenCV's imread function, and then convert the image to grayscale. Converting to grayscale is a common preprocessing step for facial detection algorithms because it simplifies the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e46359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./test_data/cary_elwes.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee4ae2",
   "metadata": {},
   "source": [
    "This block sets up the face and eye detection process. We first copy the original image to preserve it. Then we load the Haar cascade classifiers for face and eye detection. We detect faces in the grayscale image, and for each detected face, we look for eyes inside the face region. Rectangles are drawn around each face and eye, and the image is displayed in a separate window using OpenCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "069c9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig = img.copy()\n",
    "face_cascade = cv2.CascadeClassifier('./haar_cascades_classifier/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('./haar_cascades_classifier/haarcascade_eye.xml')\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3,5) \n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    \n",
    "    face_region_gray = gray[y:y+h, x:x+w] \n",
    "    face_region_color = img[y:y+h, x:x+w]\n",
    "    \n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    eyes =  eye_cascade.detectMultiScale(face_region_gray)\n",
    "    \n",
    "    for (x_eye, y_eye, w_eye, h_eye) in eyes:\n",
    "        eyes_img = cv2.rectangle(face_region_color,(x_eye,y_eye),(x_eye+w_eye,y_eye+h_eye),(0,255,0),2)\n",
    "    \n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(3000)\n",
    "cv2.destroyAllWindows()\n",
    "img = img_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3290d7ff",
   "metadata": {},
   "source": [
    "Here we define a helper function that takes an image path and attempts to detect face regions containing at least two eyes. The function returns a list of cropped face images, which will later be used for training or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26d4fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face_regions(img_path, silent = True):\n",
    "    \n",
    "    face_regions = []  #here we will store clearly visible faces (faces with 2 eyes)\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3,5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "\n",
    "        face_region_gray = gray[y:y+h, x:x+w] #face area gray\n",
    "        face_region_color = img[y:y+h, x:x+w] #face area color\n",
    "\n",
    "        eyes =  eye_cascade.detectMultiScale(face_region_gray)\n",
    "        \n",
    "        if len(eyes) >= 2:\n",
    "            face_regions.append(face_region_color)\n",
    "        \n",
    "    if len(face_regions) == 0 and silent==False:\n",
    "        print('No clear faces found.')\n",
    "        \n",
    "    return face_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f5087",
   "metadata": {},
   "source": [
    "Let's see the function in action! Here is what it does to the image of Cary Elwes we saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfb19a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = extract_face_regions('./test_data/cary_elwes.jpg', silent = False)\n",
    "plt.imshow(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae55b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =  cv2.imread('./test_data/multiple_people.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c67f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_faces = extract_face_regions('./test_data/multiple_people.jpg')\n",
    "for cr_face in cr_faces:\n",
    "    plt.figure()\n",
    "    plt.imshow(cr_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ea7c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_data = \"./raw_data/\"\n",
    "path_cr_data = \"./cr_data/\"\n",
    "\n",
    "img_folders = []\n",
    "actor_names = []\n",
    "\n",
    "for folder in os.scandir(path_raw_data):\n",
    "    if folder.is_dir():\n",
    "        img_folders.append(folder.path)\n",
    "        actor_names.append(folder.name)\n",
    "        \n",
    "# If the cropped data folder was made in a previous run, we want to remove it and remake it\n",
    "cr_data_folder = Path(path_cr_data)\n",
    "if cr_data_folder.exists() and cr_data_folder.is_dir():\n",
    "    shutil.rmtree(cr_data_folder)\n",
    "    \n",
    "os.mkdir(path_cr_data)\n",
    "\n",
    "for name in actor_names:\n",
    "    path_to_cr_actor = path_cr_data +'/'+ name\n",
    "    if not os.path.exists(path_to_cr_actor):\n",
    "        os.mkdir(path_to_cr_actor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91aa4df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_img_dictionary = {}\n",
    "\n",
    "for actor_ind in range(5):\n",
    "    actor_name = actor_names[actor_ind]\n",
    "    cr_face_paths = []\n",
    "    \n",
    "    cropped_photo_ind = 0\n",
    "    print(actor_ind)\n",
    "    for image in os.scandir(img_folders[actor_ind]):\n",
    "\n",
    "        path_to_image = img_folders[actor_ind] +'/'+image.name\n",
    "        cr_faces = extract_face_regions(path_to_image, silent = True)\n",
    "\n",
    "        path_to_cr_actor = path_cr_data + actor_name\n",
    "\n",
    "        for cr_face in cr_faces:\n",
    "            cropped_photo_ind += 1\n",
    "\n",
    "            cr_face_path = path_to_cr_actor + '/' +str(actor_name)  +str(cropped_photo_ind) +'.jpg'\n",
    "\n",
    "            cv2.imwrite(cr_face_path, cr_face)\n",
    "            \n",
    "            cr_face_paths.append(cr_face_path)\n",
    "            \n",
    "    cropped_img_dictionary[actor_name] = cr_face_paths\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f82958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
